input { stdin { } }

filter {
  mutate { replace => { "type" => "upstream" } }
  grok {
    match => [ "message", "%{IP:balancer} - %{IP:client_ip} - \[%{HTTPDATE:timestamp}\] \"%{WORD:http_verb} %{NOTSPACE:uri} (?:HTTP/%{NUMBER:http_version}|%{DATA:rawrequest})\" %{NUMBER:http_status:int} (?:%{NUMBER:bytes:int}|-) upstream %{NUMBER:upstream_s:float} request %{NUMBER:request_s:float} \[for %{HOSTNAME:domain} via %{HOSTPORT:downstream}\] %{QS:agent} %{QS:gzip_ratio}" ]

  }
  # computed fields, conversion to milliseconds for consistency with nginx accesslog.
  ruby {
    code => "event['request_ms'] = event['request_s']*1000"
  }
  ruby {
    code => "event['upstream_ms'] = event['upstream_s']*1000"
  }
  date {
    match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
}

output {
    # elasticsearch { host => localhost }
    stdout { codec => rubydebug }
}
